import{_ as s,c as e,o as t,a as o}from"./app.5c7a3dbc.js";const F=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[{"level":2,"title":"Tokenizer (Prefix Search)","slug":"tokenizer-prefix-search","link":"#tokenizer-prefix-search","children":[]},{"level":2,"title":"Add custom tokenizer","slug":"add-custom-tokenizer","link":"#add-custom-tokenizer","children":[]}],"relativePath":"api/tokenizer.md"}'),n={name:"api/tokenizer.md"},a=o(`<h2 id="tokenizer-prefix-search" tabindex="-1">Tokenizer (Prefix Search) <a class="header-anchor" href="#tokenizer-prefix-search" aria-hidden="true">#</a></h2><p>Tokenizer affects the required memory also as query time and flexibility of partial matches. Try to choose the most upper of these tokenizer which fits your needs:</p><table><thead><tr><th>Option</th><th>Description</th><th>Example</th><th>Memory Factor (n = length of word)</th></tr></thead><tbody><tr><td><strong>&quot;strict&quot;</strong></td><td>index whole words</td><td><code>foobar</code></td><td>* 1</td></tr><tr><td><strong>&quot;forward&quot;</strong></td><td>incrementally index words in forward direction</td><td><code>fo</code>obar <br><code>foob</code>ar</td><td>* n</td></tr><tr><td><strong>&quot;reverse&quot;</strong></td><td>incrementally index words in both directions</td><td>foob<code>ar</code> <br>fo<code>obar</code></td><td>* 2n - 1</td></tr><tr><td><strong>&quot;full&quot;</strong></td><td>index every possible combination</td><td>fo<code>oba</code>r <br>f<code>oob</code>ar</td><td>* n * (n - 1)</td></tr></tbody></table><h2 id="add-custom-tokenizer" tabindex="-1">Add custom tokenizer <a class="header-anchor" href="#add-custom-tokenizer" aria-hidden="true">#</a></h2><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>A tokenizer split words/terms into components or partials.</p></div><p>Define a private custom tokenizer during creation/initialization:</p><div class="language-js"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki"><code><span class="line"><span style="color:#C792EA;">var</span><span style="color:#A6ACCD;"> index </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">new</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">FlexSearch</span><span style="color:#A6ACCD;">(</span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#82AAFF;">tokenize</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">function</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">str</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#F07178;">    </span><span style="color:#89DDFF;">return</span><span style="color:#F07178;"> </span><span style="color:#A6ACCD;">str</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">split</span><span style="color:#F07178;">(</span><span style="color:#89DDFF;">/</span><span style="color:#C3E88D;">\\s-</span><span style="color:#A6ACCD;">\\/</span><span style="color:#89DDFF;">/</span><span style="color:#F78C6C;">g</span><span style="color:#F07178;">)</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">  </span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#89DDFF;">}</span><span style="color:#A6ACCD;">)</span><span style="color:#89DDFF;">;</span></span>
<span class="line"></span></code></pre></div><blockquote><p>The tokenizer function gets a string as a parameter and has to return an array of strings representing a word or term. In some languages every char is a term and also not separated via whitespaces.</p></blockquote>`,8),r=[a];function l(p,c,i,d,y,h){return t(),e("div",null,r)}const u=s(n,[["render",l]]);export{F as __pageData,u as default};
